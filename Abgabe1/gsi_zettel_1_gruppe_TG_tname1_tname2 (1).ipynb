{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d40356",
   "metadata": {},
   "source": [
    "# Übungszettel 1 - Grundlagen, Resourcen, Annotationen\n",
    "### Abgabefrist: Freitag, 28. April 2023, 9:59 Uhr\n",
    "\n",
    "_Umbennenung des Jupyter Notebooks mit Gruppenname und Techfak-Kürzel!_\n",
    "\n",
    "Punkte insgesamt möglich: _20 Punkte_\n",
    "\n",
    "## Aufgabe 1: _(5 Punkte)_\n",
    "Dem Übunszettel ist ein Ausschnitt aus dem Film \"2001: A Space Odyssey\" (`2001.mp4`) und ein Video `office-scene.mp4` beigelegt. Speichert diese im gleichen Verzeichnis wie das Jupyter Notebook oder schaut euch diese in einem eigenen Player an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<center>\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"./2001.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"./office-scene.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17c614",
   "metadata": {},
   "source": [
    "### A1.1: _(3 Punkte)_\n",
    "Überlegt welche Fähigkeiten und Wissen über die natürlichsprachliche Kommunikation der Computer HAL implementieren muss, um die dargestellte Kommunikationsepisode zu ermöglichen. Nennt mindestens sechs Punkte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c572ea14",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    <hier Lösung der Teilaufgabe 1.1 (Enter oder Doppelklick auf Zelle)>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55eef58",
   "metadata": {},
   "source": [
    "### A1.2: _(2 Punkte)_\n",
    "Erklärt den Begriff \"Overlap\" in der natürlichsprachlichen Kommunikation. Ergänzt eure Erläuterung um ein Beispiel aus dem Video `office-scene.mp4`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6206655",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    <hier Lösung der Teilaufgabe 1.2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4644927",
   "metadata": {},
   "source": [
    "## Aufgabe 2: _(12 Punkte)_\n",
    "Für komplexe Annotationen von Sprach- sowie Gestendaten wird im Allgemeinen Software wie [Praat](https://www.fon.hum.uva.nl/praat/) und [ELAN](https://archive.mpi.nl/tla/elan/download) verwendet. Für die naive Transkribierung soll hier das Tool [Label Studio](https://labelstud.io/) genügen.\n",
    "Installiert dieses mittels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b44fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install label-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb0516",
   "metadata": {},
   "source": [
    "Startet die Label Studio Instanz und öffnet den erschienenden Link _(http://0.0.0.0:8080/)_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf01143",
   "metadata": {},
   "outputs": [],
   "source": [
    "!label-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132da85f",
   "metadata": {},
   "source": [
    "Gebt eine Zeichenreihenfolge im `Sign up`-Reiter ein, welche dem Pattern einer Email-Adresse entspricht und ein Passwort (test@test.de, 123456789). Gegebenfalls loggt euch mit den Daten ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ae606",
   "metadata": {},
   "source": [
    "### A2.1: _(8 Punkte)_\n",
    "Transkribiert die das Gespräch aus der `office-scene.mp4`. Benutzt hierfür die `office-scene.wav` Audiodatei.\n",
    "1. Legt dafür ein **neues Projekt** in Label Studio an.\n",
    "\n",
    "    a) Wählt einen Namen für das Projekt.\n",
    "    \n",
    "    b) **Importiert** die WAV-Datei.\n",
    "    \n",
    "    c) Erstellt ein **custom template** mit folgendem HTML-Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404956cd",
   "metadata": {},
   "source": [
    "    <View>\n",
    "      <Labels name=\"labels\" toName=\"audio\">\n",
    "        <Label value=\"Hendrik\" />\n",
    "        <Label value=\"Christopher\" />\n",
    "      </Labels>\n",
    "      <AudioPlus name=\"audio\" value=\"$audio\"/>\n",
    "      <TextArea name=\"transcription\" toName=\"audio\"\n",
    "                rows=\"2\" editable=\"true\"\n",
    "                perRegion=\"true\" required=\"true\" />\n",
    "    </View>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6bb3e",
   "metadata": {},
   "source": [
    "2. Transkribiert den Dialog wortwörtlich (in deutscher Sprache) und in der Granularität von Äußerungen. **Hendrik** ist die Person, die zuerst spricht. Man kann mit `Strg + Scrollen` in der Darstellung der Audiodatei zoomen. Versucht für die Aufgabe 3 möglicht genau Start und Ende der Äußerungen zu markieren.\n",
    "  \n",
    "  _Hinweis:_ Wie in der Vorlesung bereits erörtert, gilt die Spracherkennung als \"gelöstes\" Problem. Qualitativ gibt es allerdings deutliche Unterschiede zwischen Deutsch und Englisch. Als eines der besten (und frei verfügbaren) Modelle gilt **Whisper** von OpenAI. Als _Entwurf_ für eure Transkriptionstexte bietet sich ein solches Modell an. [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) ermöglicht es das Modell optimiert auf der eigenen CPU laufen zu lassen. Generell gibt es auch [Webseiten](https://replicate.com/openai/whisper), die kostenlos das Modell laufen lassen. Ansonsten kann man auch ohne solche Modelle das 1-minütige Gespräch transkribieren.\n",
    "  \n",
    "3. In Label Studio: `Submit` eure Transkription und exportiert in der Übersicht des Projekts eure Annotationen als JSON Datei.\n",
    "4. **Stopt die Ausführung** von Label Studio im Jupyter Notebook (ggf. durch \"Interrupt Kernel ■\").\n",
    "6. **Fügt** eure Annotationen als JSON Code **unten ein**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Antwort hier\n",
    "transcript = json.loads(\"\"\"\n",
    "<ersetz mich>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f449b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(annotations):\n",
    "    \"\"\"Combine speaker and text annotation.\"\"\"\n",
    "    output = []\n",
    "    current_sentence = {}\n",
    "    for annotations_result in annotations: # annotation sessions\n",
    "        for result in annotations_result[\"result\"]:\n",
    "            assert \"value\" in result, \"Wrong format\"\n",
    "            assert \"id\" not in current_sentence or result[\"value\"][\"id\"] == current_sentence[\"id\"], \"Wrong ordering in annotation\"\n",
    "            current_sentence.update(result[\"value\"])\n",
    "            if \"labels\" in current_sentence and \"text\" in current_sentence:\n",
    "                current_sentence[\"labels\"] = \",\".join(current_sentence[\"labels\"])  # for multiple labels \n",
    "                current_sentence[\"text\"] = \";\".join(current_sentence[\"text\"])  # for multiple text annotations\n",
    "                current_sentence[\"start\"] = int(current_sentence[\"start\"]*1000)  # to ms\n",
    "                current_sentence[\"end\"] = int(current_sentence[\"end\"]*1000)  # to ms\n",
    "                output.append(current_sentence)\n",
    "                current_sentence = {}\n",
    "    return output\n",
    "transcript = postprocessing(transcript[0][\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f120d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def convert_ms_to_datetime(data):\n",
    "    for sentence in data:\n",
    "        sentence[\"start_dt\"] = pd.to_datetime(sentence[\"start\"], unit=\"ms\")\n",
    "        sentence[\"end_dt\"] = pd.to_datetime(sentence[\"end\"], unit=\"ms\")\n",
    "    return data\n",
    "\n",
    "# Plot Transcript\n",
    "figure = px.timeline(convert_ms_to_datetime(transcript), y=\"labels\", color=\"labels\", x_start='start_dt', x_end='end_dt', hover_data=[\"labels\", \"text\"], text=\"text\")\n",
    "figure.update_layout(xaxis=dict(tickformat=\"%M:%S.%f\"), xaxis_title=\"Zeit\", yaxis_title=\"Sprecher\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2c299",
   "metadata": {},
   "source": [
    "### A2.2: _(1 Punkt)_\n",
    "Welche Information **fehlen** im Vergleich zu einem GAT-2 Basistranskript bzw. Feintranskript in eurem Transkription?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602a1c0",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    <hier Lösung der Teilaufgabe 2.3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266203f",
   "metadata": {},
   "source": [
    "### A2.4: _(3 Punkt)_\n",
    "Berechnet den **Floor Transfer Offset** (zeitlichen Abstand zwischen den Sprechwechseln / Floor Übergabe) für euere Transkription. Zwischenbemerkungen (kompletter Overlaps) sind dabei zu ignorieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_transfer_offset(transcript_data):\n",
    "    transfer_offsets = []  # list of offsets (ms)\n",
    "    \n",
    "    # Antwort hier  \n",
    "    \n",
    "    return transfer_offsets\n",
    "\n",
    "offsets = floor_transfer_offset(transcript)\n",
    "\n",
    "print(offsets)\n",
    "figure = px.histogram(offsets).update_layout(xaxis_title=\"milliseconds overlap\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b575fb",
   "metadata": {},
   "source": [
    "## Aufgabe 3: _(3 Punkte)_\n",
    "\n",
    "### A3.1: _(1 Punkt)_\n",
    "Wofür wird die **Cohen's Kappa** Metrik verwendet? Wie wird sie berechnet für zwei Annotationen mit einer variablen Anzahl an Kategorien $C$ (Formel) und wie werden deren Bestandteile berechnet (Formel)? Markdown unterstützt Latex Mathe Formeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b07e7",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    Zweck: <Antwort>\n",
    "\n",
    "    Formel: \n",
    "$$\\kappa = $$\n",
    "    \n",
    "$$...$$\n",
    "    \n",
    "$$...$$\n",
    "    \n",
    "$$...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bcdd9",
   "metadata": {},
   "source": [
    "### A3.2: _(1 Punkt)_:\n",
    "Berechnet für folgende Annotationen Cohen's Kappa (mit zwischen Ergebnissen). Entweder per Hand (Antwortzelle in Markdown ändern + Latex Umgebung mit $) oder per Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c24e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "data = {\"matrix\": [[12, 2, 5, 0], [2, 13, 2, 0], [0, 1, 9, 2], [2, 1, 4, 10]], \"categories\": [\"C1\", \"C2\", \"C3\", \"C4\"]}\n",
    "\n",
    "display(HTML(\"<table><tr><th>A1/A2</th><th>{}</th></tr><tr>{}</tr></table>\".format(\"</th><th>\".join(data[\"categories\"]), \"</tr><tr>\".join(f\"<th>{data['categories'][i]}</th><td>{'</td><td>'.join(str(entry) for entry in row)}</td>\" for i, row in enumerate(data['matrix'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Antwort:\n",
    "\n",
    "print(\"Zwischenergebnisse:\", \"\")\n",
    "print(\"Cohen's Kappa Wert:\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b7b46",
   "metadata": {},
   "source": [
    "### A3.3: _(1 Punkt)_\n",
    "Wie kann man den Wert aus A3.2 interpretieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6ccde",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    <Antwort>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7731110",
   "metadata": {},
   "source": [
    "------\n",
    "Geben Sie dieses umbenannte und bearbeitete Jupyter Notebook im Moodle ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b49fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
