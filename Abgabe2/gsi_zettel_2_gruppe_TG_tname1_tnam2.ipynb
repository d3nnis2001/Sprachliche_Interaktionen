{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Übungszettel 1 - Morphologie & Syntax (1. Teil)\n",
    "### Abgabefrist: Freitag, 12. Mai 2023, 9:59 Uhr\n",
    "\n",
    "_Umbennenung des Jupyter Notebooks mit Gruppenname und Techfak-Kürzel!_\n",
    "\n",
    "Punkte insgesamt möglich: _20 Punkte_\n",
    "\n",
    "## Aufgabe 1: _(5 Punkte)_\n",
    "\n",
    "### A1.1: _(3 Punkte)_\n",
    "Erklärt die Begriffe **Morphologie**, **Morphem** und **Affix**. Benutzt für die Erklärung des Begriffs **Affix** die folgenden Beispielwörtern (geht dabei auf alle fünf ein):\n",
    "\n",
    "* Kaffeesatzleserin\n",
    "* laufend\n",
    "* verwerfen\n",
    "* einzunehmen\n",
    "* verspielt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    * Eine Morphologie ist der Bereich der Linguistik, welcher sich mit der Struktur von Wörtern beschäftigt.\n",
    "    * Ein Morphem ist die kleinste bedeutungstragende Einheit auf der Ebene des Sprachsystems. Jedes Wort wird aus Morphemen gebildet. Dabei kann ein Morphem entweder alleine in einen Wort auftreten oder in Kombination mit anderen Morphemen.\n",
    "    * Der Affix ist ebenfalls eine Art von Morphem welcher zur Kombination von Morphemen benutzt werden kann, um die Bedeutung eines Wortes zu erweitern oder zu verändern. Dabei gibt es 2 verschiedene Arten von Affixen. Einmal den Präfix welcher am Anfang eines Wortes auftaucht und einen Suffix, welcher das Ende eines Wortes bildet.\n",
    "---\n",
    "    - Kaffeesatzleserin | In diesem Fall besteht das Wort aus einem normalen Morphem und 2 Affixen. Einen Präfix (Kaffee) und einen Suffix (leserin)\n",
    "    - laufend | Dieses Wort besteht einmal aus dem Wort (lauf). Allerdings verändert das end welches wieder ein Suffix ist die Bedeutung des Wortes im zeitlichen Sinne. \n",
    "    - verwerfen | Besteht wieder aus 3 grundlegenden Teilen. Den eigentlichen Morphem (werf), den Präfix (ver) und den Suffix (en). Dabei verändert der Präfix das Wort in diesem Fall negativ\n",
    "    - einzunehmen | hier gibt es zwei grundlegende Präfixe die das Morphem (nehmen) verändern. Einmal ein und einmal zu\n",
    "    - verspielt | Hier ist wieder der Fall das es einen Präfix gibt (ver) zum Morphem (spielt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.2: _(1 Punkte)_\n",
    "Erklärt das theoretische Grundprinzip des morphologischen Parsings mit zwei Ebenen und die dafür notwendigen linguistischen Informationen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "\n",
    "    Das morphologische Parsing beschreibt einen Prozess, bei welchen ein Satz oder ein Wort in Morpheme zerlegt werden. Dabei unterscheidet man zwischen den folgenden Ebenen: \n",
    "    1. Lexikon Ebene: Hier werden alle Wörter zugeordnet. Dabei wird eine Liste von Wortstämmen und Affixe inkl. Basisinformationen erstellt wie z.B. wird geschaut ob es sich um ein Verb, Adjektiv oder Nomen handelt. \n",
    "\n",
    "    2. Morphologie Ebene: Hier werden die Wörter in ihre Bestandteile zerlegt (Affixe)\n",
    "\n",
    "    Notwendigen linguistischen Informationen: \n",
    "\n",
    "    - Wissen über Affixe und wie diese die Bedeutung der Wörter verändern\n",
    "    - Eigenschaften der Wörter wie z.B. Kasus des Wortes\n",
    "    - Wissen über die verschiedenen Zeitformen bei z.B. Verben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.3: _(1 Punkte)_\n",
    "Nennt zwei Eigenschaften, welche Finite-State-Transducer besonders interessant für das morphologische Parsing machen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    1. Flexibel: Der Finite-State-Tranducer ist sehr flexibel und kann sich leicht an verschiedene Sprachen anpassen. \n",
    "2. Effizient: Der Finite-State-Transducer ist sehr effizient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: _(10 Punkte)_\n",
    "Installiert graphviz, falls noch nicht auf eurem Rechner vorhanden.\n",
    "```bash\n",
    "sudo apt-get install graphviz\n",
    "```\n",
    "oder https://graphviz.org/download/\n",
    "\n",
    "Um graphviz in Python zu benutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /Users/dennisschielke/Desktop/test/.conda/lib/python3.9/site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Tuple, Iterable\n",
    "\n",
    "class FiniteStatePlot:\n",
    "    \"\"\" info: do not use \"_s_\" as a node name \"\"\"\n",
    "    \n",
    "    def __init__(self, transitions:Dict[str, Tuple[str, str]]=None, final_states:Iterable[str]=None, start_state:str=None):\n",
    "        self.start_state = start_state\n",
    "        self.transitions = defaultdict(list)  # entries: list of (target, condition)  / adjacency list\n",
    "        if transitions:\n",
    "            self.transitions.update(transitions)\n",
    "        self.final_states = final_states if final_states else set()\n",
    "    \n",
    "    def transition(self, source, target, condition=\"\"):\n",
    "        \"\"\" create transition from source node to target node with a condition. \"\"\"\n",
    "        self.transitions[source].append((target, condition))\n",
    "    \n",
    "    def state(self, name, is_final=False, is_start=False):\n",
    "        \"\"\" Assign final and start properties to a state. (Add the state to the adjacency list for counting states) \"\"\"\n",
    "        if name not in self.transitions:\n",
    "            self.transitions[name] = []\n",
    "        if is_final:\n",
    "            self.final_states.update([name])\n",
    "        elif name in self.final_states:\n",
    "            self.final_states.remove(name)\n",
    "        if is_start:\n",
    "            self.start_state = name\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\" plot the finite state machine with graphviz in jupyter-notebook if the method call is the last statement in a jupyter cell.\"\"\"\n",
    "        \n",
    "        return graphviz.Source(f\"\"\"\n",
    "        digraph finite_state_machine {{\n",
    "            fontname=\"Helvetica,Arial,sans-serif\"\n",
    "            node [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "            edge [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "            rankdir=LR;\n",
    "            {f\"node [shape = point ]; _s_\" if self.start_state else \"\"}\n",
    "            node [shape = doublecircle]; {\" \".join(self.final_states) + (\";\" if self.final_states else \"\")}\n",
    "            node [shape = circle];\n",
    "            {f\"_s_ -> {self.start_state};\" if self.start_state else \"\"}\n",
    "            {\"\".join(f'{s} -> {t} [label = \"{condition}\"]' for s, transitions in self.transitions.items() for (t, condition) in transitions)}\n",
    "        }}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2.1: _(4 Punkte)_\n",
    "Erstellt einen _deterministischen_ Finite-State Lexikon, welches **alle** Wörter (+ `#`) aus dem Dialog (in der `text`-Variable) (Satzzeichen und die Sprechernamen können ignoriert werden) parsen kann. Implementiert dafür entweder die Klassenmethode `create(self, words)` welche für eine Menge an Wörtern das FS-Lexikon erstellt oder fügt von Hand alle Transitionen ein, die eine FS-Lexikon braucht, um genau diese Wörter zu parsen. Vergesst in beiden Fällen nicht den Startzustand und eure Endzustände zu definieren.\n",
    "\n",
    "Relevant für _deterministisch_: Übergänge von einem Zustand dürfen nicht mehrdeutig sein und keine \"ε\" Übergänge. Negatives Beispiel: Zustand q0 hat Übergänge \"abc\" und \"ab\" in zwei unterschiedliche Zustände. Nicht deterministisch, da die Überprüfung für beide Übergänge wahr sein könnten. In dieser Aufgabe sind auch Übergänge, die deterministisch wären, aber in den gleichen Zustand übergehen nicht erlaubt.\n",
    "\n",
    "- Das Wortgrenzzeichen \"#\" soll **immer alleine** (ohne andere Buchstaben) in den Endzustand führen.\n",
    "- Ihr dürft für die Implementierung weitere Methoden zur Lexikon-Klasse hinzufügen.\n",
    "- Für die Implementierung der `create`-Methode bietet es sich an immer nur einen Buchstaben für einen Übergang zu betrachten. Die `reduce`-Methode versucht diesen \"aufgeblähten\" FSL zu reduzieren, um den Plot zu verkleinern.\n",
    "- Die Übergänge werden mittels einer Adjazenzliste repräsentiert. Die Einträge in der Liste sind Tuple mit dem nächsten Zustand und der Übergangsbedingung.\n",
    "- Der FSL muss NICHT komprimiert sein (z. B. den Übergang `#` oder das Mehrzahl \"s\" oder He-She-It \"s\" möglichst häufig wiederverwenden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiniteStateLexicon(FiniteStatePlot):\n",
    "    \n",
    "    def __init__(self, transitions:Dict[str, Tuple[str, str]]=None, final_states:Iterable[str]=None, start_state:str=None):\n",
    "        super().__init__(transitions, final_states, start_state)\n",
    "        self.reset()\n",
    "        \n",
    "    def run(self, word):\n",
    "        if not self.current_state:\n",
    "            return False\n",
    "        while True:\n",
    "            for next_state, condition in self.transitions[self.current_state]:\n",
    "                #  startswith only for reduced finite state lexicon, == should be enough for single letter transitions\n",
    "                if word.startswith(condition):\n",
    "                    self.current_state = next_state\n",
    "                    word = word[len(condition):]\n",
    "                    break\n",
    "            else:\n",
    "                return False\n",
    "            if not word:\n",
    "                return self.current_state in self.final_states\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_state = self.start_state\n",
    "    \n",
    "    def test_determinism(self):\n",
    "        for _, transitions in self.transitions.items():\n",
    "            last = \";\"\n",
    "            for x in sorted([t for _, t in transitions]):\n",
    "                assert x and not x.startswith(last), f\"Determinism failed: {x, last}\"\n",
    "                assert x != \"\", f\"Determinism failed, found Epsilon transition\"\n",
    "                last = x[0]\n",
    "    \n",
    "    def test_only_single_transitions(self):\n",
    "        if not self.transitions.values():\n",
    "            return True\n",
    "        for transitions in self.transitions.values():\n",
    "            if any(len(c) > 1 for _, c in transitions):\n",
    "                return False\n",
    "            \n",
    "    def reduce(self):\n",
    "        \"\"\" for reduced graph \"\"\"\n",
    "        transitions = self.transitions.copy()\n",
    "        not_visited_states = list(transitions.keys())  # copy\n",
    "        cur_state = self.start_state\n",
    "        while not_visited_states:\n",
    "            if cur_state in not_visited_states:\n",
    "                not_visited_states.remove(cur_state)\n",
    "            if cur_state not in transitions or not transitions[cur_state]:\n",
    "                cur_state = not_visited_states.pop(0)\n",
    "                continue\n",
    "            del_cur_state_transitions = []\n",
    "            for i in range(len(self.transitions[cur_state])):\n",
    "                t, c = self.transitions[cur_state][i]\n",
    "                simple_nodes, conditions = [], []\n",
    "                while len(transitions[t]) == 1:\n",
    "                    simple_nodes.append(t)\n",
    "                    conditions.append(c)\n",
    "                    t, c = transitions[t][0]\n",
    "                if c != \"#\":  # '#' still in single transition\n",
    "                    simple_nodes.append(t)\n",
    "                    conditions.append(c)\n",
    "                if simple_nodes:\n",
    "                    transitions[cur_state].append((simple_nodes[-1], \"\".join(conditions)))\n",
    "                    del_cur_state_transitions.append(i)\n",
    "                    for n in simple_nodes[:-1]:\n",
    "                        del transitions[n]\n",
    "            for i in reversed(del_cur_state_transitions):\n",
    "                self.transitions[cur_state].pop(i)\n",
    "            cur_state = not_visited_states.pop(0)\n",
    "        self.transitions = transitions\n",
    "    \n",
    "    def create(self, words):\n",
    "        assert self.test_only_single_transitions(), \"'create'-method cannot add words to a lexicon that is reduced\"\n",
    "       \n",
    "        # Eure Lösung hier oder erstellt für genau diese Wörter von Hand einen Finite State Lexikon und fügt die Transitions und States einzeln, außerhalb dieser Klasse hinzu\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Paul: did you see the game or did you go fishing?\n",
    "Joe: I was fishing and caught a squid.\n",
    "Paul: Have you seen, last time I caught many squids.\n",
    "\"\"\"\n",
    "my_lexikon = FiniteStateLexicon()\n",
    "\n",
    "# convert text to set of words with \"#\"\n",
    "lexicon_words = set(map(lambda x: f\"{''.join(filter(lambda x: x.isalpha(), x))}#\", filter(lambda x: \":\" not in x, text.split())))  # remove punctuation, speaker annotation, repetitions\n",
    "my_lexikon.create(lexicon_words)\n",
    "\n",
    "## Oder hier Lösung von Hand: Fügt die Transitionen und States einzeln hinzu die nötig sind, um diese Wörter zu parsen.\n",
    "# my_lexicon.transition(source=\"q0\", target=\"q1\", condition=\"a\")\n",
    "# my_lexicon.state(\"q0\", is_start=True)\n",
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon cannot parse word 'squid#'\n",
      "Lexicon cannot parse word 'Have#'\n",
      "Lexicon cannot parse word 'squids#'\n",
      "Lexicon cannot parse word 'or#'\n",
      "Lexicon cannot parse word 'was#'\n",
      "Lexicon cannot parse word 'seen#'\n",
      "Lexicon cannot parse word 'see#'\n",
      "Lexicon cannot parse word 'you#'\n",
      "Lexicon cannot parse word 'a#'\n",
      "Lexicon cannot parse word 'and#'\n",
      "Lexicon cannot parse word 'many#'\n",
      "Lexicon cannot parse word 'go#'\n",
      "Lexicon cannot parse word 'last#'\n",
      "Lexicon cannot parse word 'the#'\n",
      "Lexicon cannot parse word 'fishing#'\n",
      "Lexicon cannot parse word 'I#'\n",
      "Lexicon cannot parse word 'game#'\n",
      "Lexicon cannot parse word 'time#'\n",
      "Lexicon cannot parse word 'caught#'\n",
      "Lexicon cannot parse word 'did#'\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/backend/execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m---> 79\u001b[0m     proc \u001b[39m=\u001b[39m _run_input_lines(cmd, input_lines, kwargs\u001b[39m=\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/backend/execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[39m*\u001b[39m, kwargs):\n\u001b[0;32m---> 99\u001b[0m     popen \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, stdin\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    101\u001b[0m     stdin_write \u001b[39m=\u001b[39m popen\u001b[39m.\u001b[39mstdin\u001b[39m.\u001b[39mwrite\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/IPython/core/formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    971\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    973\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m         \u001b[39mreturn\u001b[39;00m method(include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr_image_svg_xml\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipe(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msvg\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mSVG_ENCODING)\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipe\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m          \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m          renderer: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m          engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m          encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m        '<?xml version='\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_legacy(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    105\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    106\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    107\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    108\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    109\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    110\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@_tools\u001b[39m\u001b[39m.\u001b[39mdeprecate_positional_args(supported_number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe_legacy\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m                  \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                  encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_future(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    123\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    124\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    125\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    126\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    127\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(encoding) \u001b[39mis\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding):\n\u001b[1;32m    148\u001b[0m         \u001b[39m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_lines_string(\u001b[39m*\u001b[39;49margs, encoding\u001b[39m=\u001b[39;49mencoding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m         raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_lines(\u001b[39m*\u001b[39margs, input_encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/backend/piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    206\u001b[0m cmd \u001b[39m=\u001b[39m dot_command\u001b[39m.\u001b[39mcommand(engine, \u001b[39mformat\u001b[39m,\n\u001b[1;32m    207\u001b[0m                           renderer\u001b[39m=\u001b[39mrenderer,\n\u001b[1;32m    208\u001b[0m                           formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    209\u001b[0m                           neato_no_op\u001b[39m=\u001b[39mneato_no_op)\n\u001b[1;32m    210\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_lines\u001b[39m\u001b[39m'\u001b[39m: input_lines, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m: encoding}\n\u001b[0;32m--> 212\u001b[0m proc \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mrun_check(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, quiet\u001b[39m=\u001b[39;49mquiet, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m proc\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/Desktop/test/.conda/lib/python3.9/site-packages/graphviz/backend/execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x109deaa30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in lexicon_words:\n",
    "    if not my_lexikon.run(w):\n",
    "        print(f\"Lexicon cannot parse word '{w}'\")\n",
    "    my_lexikon.reset()\n",
    "my_lexikon.test_determinism()\n",
    "my_lexikon.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon cannot parse word 'last#'\n",
      "Lexicon cannot parse word 'game#'\n",
      "Lexicon cannot parse word 'a#'\n",
      "Lexicon cannot parse word 'time#'\n",
      "Lexicon cannot parse word 'and#'\n",
      "Lexicon cannot parse word 'fishing#'\n",
      "Lexicon cannot parse word 'go#'\n",
      "Lexicon cannot parse word 'was#'\n",
      "Lexicon cannot parse word 'see#'\n",
      "Lexicon cannot parse word 'you#'\n",
      "Lexicon cannot parse word 'Have#'\n",
      "Lexicon cannot parse word 'did#'\n",
      "Lexicon cannot parse word 'squid#'\n",
      "Lexicon cannot parse word 'or#'\n",
      "Lexicon cannot parse word 'seen#'\n",
      "Lexicon cannot parse word 'caught#'\n",
      "Lexicon cannot parse word 'squids#'\n",
      "Lexicon cannot parse word 'many#'\n",
      "Lexicon cannot parse word 'the#'\n",
      "Lexicon cannot parse word 'I#'\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/backend/execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m---> 79\u001b[0m     proc \u001b[39m=\u001b[39m _run_input_lines(cmd, input_lines, kwargs\u001b[39m=\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/backend/execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[39m*\u001b[39m, kwargs):\n\u001b[0;32m---> 99\u001b[0m     popen \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, stdin\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    101\u001b[0m     stdin_write \u001b[39m=\u001b[39m popen\u001b[39m.\u001b[39mstdin\u001b[39m.\u001b[39mwrite\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/formatters.py:972\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    969\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    971\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m         \u001b[39mreturn\u001b[39;00m method(include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    973\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr_image_svg_xml\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipe(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msvg\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mSVG_ENCODING)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipe\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m          \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m          renderer: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m          engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m          encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m        '<?xml version='\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_legacy(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    105\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    106\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    107\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    108\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    109\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    110\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@_tools\u001b[39m\u001b[39m.\u001b[39mdeprecate_positional_args(supported_number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe_legacy\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m                  \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                  encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_future(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    123\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    124\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    125\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    126\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    127\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(encoding) \u001b[39mis\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding):\n\u001b[1;32m    148\u001b[0m         \u001b[39m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_lines_string(\u001b[39m*\u001b[39;49margs, encoding\u001b[39m=\u001b[39;49mencoding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m         raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_lines(\u001b[39m*\u001b[39margs, input_encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/backend/piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    206\u001b[0m cmd \u001b[39m=\u001b[39m dot_command\u001b[39m.\u001b[39mcommand(engine, \u001b[39mformat\u001b[39m,\n\u001b[1;32m    207\u001b[0m                           renderer\u001b[39m=\u001b[39mrenderer,\n\u001b[1;32m    208\u001b[0m                           formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    209\u001b[0m                           neato_no_op\u001b[39m=\u001b[39mneato_no_op)\n\u001b[1;32m    210\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_lines\u001b[39m\u001b[39m'\u001b[39m: input_lines, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m: encoding}\n\u001b[0;32m--> 212\u001b[0m proc \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mrun_check(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, quiet\u001b[39m=\u001b[39;49mquiet, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m proc\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/graphviz/backend/execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x112ff2640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lexikon.reduce()\n",
    "for w in lexicon_words:\n",
    "    if not my_lexikon.run(w):\n",
    "        print(f\"Lexicon cannot parse word '{w}'\")\n",
    "    my_lexikon.reset()\n",
    "my_lexikon.test_determinism()\n",
    "my_lexikon.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2.2: _(6 Punkte)_\n",
    "Finite-State Transducer: Die Konvertierungsfunktion `run` implementieren und erstellen/bauen des Transducers (`create`-Methode implementieren oder von Hand).\n",
    "\n",
    "- Der Transducer soll/darf **nicht** deterministisch sein. Epsilon-Übergänge sind erwünscht und werden mit einem leeren String (`\"\"`) umgesetzt. Es gibt deshalb auch eine Liste an aktuellen Zuständen, anstatt nur einen Zustand. Es können deshalb, auch (in der Theorie) mehrere Ergebnisse existieren, z. B. das Wort `run` könnte als Nomen und Verb interpretiert werden.\n",
    "- Die `run`-Methode soll deshalbt eine \"Generator\"-Funktion sein (infos [1](https://realpython.com/introduction-to-python-generators/), [2](https://www.tutorialsteacher.com/python/python-generator)).Mit `yield \"1234\"` \"werft\" ihr ein Ergebnis zurück und die Funktion wird an diesem Abschnitt weiter ausgeführt, sollte weitere Ergebnisse angefragt werden. `return` bricht die Iteration ab.\n",
    "- Ihr dürft auch hier weitere Methoden zur Klasse hinzufügen für die Implementierung.\n",
    "- Die Instanzen der `InOut` Klasse soll die Bedingungen des Transducers darstellen (`transition(\"q0\", \"q1\", InOut(\"a\", \"b\"))`).\n",
    "\n",
    "**Wichtig:** Stellt die morphologische Struktur nach dem Grundwort in einzelnen Übergängen dar (`+N`, `+Sg`, ...) wie in Vorlesung 3 auf Folie 28. Die Wortgrenze soll dabei im letzten Übergang bearbeitet werden und die Plural (`^s#`) Erkennung soll auch mit dem morphologischen Output `+Pl` in einem Übergang bearbeitet werden. Auch hier muss der Transducer NICHT minimal sein (/morphologische Übergänge häufig wiederverwenden), aber die Morpheme/Stammwort möglichst gruppieren (wie im Finite State Lexikon), wenn möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InOut:\n",
    "    \"\"\" Class for a transducer condition in a FiniteStatePlot \"\"\"\n",
    "    def __init__(self, in_, out_):\n",
    "        self.in_ = in_\n",
    "        self.out_ = out_\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.in_ if self.in_ else 'ε'}:{self.out_ if self.out_ else 'ε'}\"\n",
    "\n",
    "\n",
    "class FiniteStateTransducer(FiniteStatePlot):\n",
    "    \n",
    "    def __init__(self, transitions:Dict[str, Tuple[str, str]]=None, final_states:Iterable[str]=None, start_state:str=None):\n",
    "        super().__init__(transitions, final_states, start_state)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_states = []\n",
    "        \n",
    "    def state_has_epsilon_transition(self, state):\n",
    "        return any([io.in_ == \"\" for _, io in self.transitions[state]])\n",
    "    \n",
    "    def new_state(self):\n",
    "        name = f\"q{len(self.transitions)}\"\n",
    "        self.state(name)\n",
    "        return name\n",
    "    \n",
    "    def run(self, word):\n",
    "        # Eure Lösung wie der Transducer eine Wort in seine morphologische Struktur konvertiert. Bedenkt: Dieser kann auch nicht deterministisch sein (mehrere aktuelle/aktive Zustände besitzen).\n",
    "        \n",
    "        # yield \"abcd+N+Pl\"\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def create(self, words_and_output):\n",
    "        # Eure Lösung hier, wie ein Transducer mittels einer gegebenen Menge an Wort-Morphologische-Struktur Daten erstellt wird.\n",
    "        # Benutzt die Klasse InOut für die condition im FiniteStatePlot/self.transitions\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_structure = [\n",
    "    ('see#', 'see+V+Pr'),\n",
    "    ('game#', 'game+N+Sg'),\n",
    "    ('fish#', 'fish+N+Sg'),\n",
    "    ('catching#', 'catch+V+Prs'),\n",
    "    ('fishing#', 'fishing+N+Sg'),\n",
    "    ('caught#', 'catch+V+Pst'),\n",
    "    ('squid#', 'squid+N+Sg'),\n",
    "    ('seen#', 'see+V+Pst'),\n",
    "    ('squid^s#', 'squid+N+Pl'),\n",
    "]\n",
    "fst = FiniteStateTransducer()\n",
    "fst.create(morph_structure)\n",
    "\n",
    "## Oder erstelle einen Transducer hier, der nur genau diese Wörter parsen kann, per Hand:\n",
    "# fst.transition(\"q0\", ...)\n",
    "\n",
    "for w, morph in morph_structure:\n",
    "    if not any(result == morph for result in fst.run(w)):\n",
    "        print(f\"Transducer cannot convert '{w}' to '{morph}'.\")\n",
    "    fst.reset()\n",
    "fst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: _(5 Punkte)_\n",
    "Wechsel zur 4. Vorlesung: Syntax (Sätze).\n",
    "### A3.1: _(1 Punkte)_\n",
    "Erklärt den Begriff **Konstituente** und inwiefern dieser für die grammatische Analyse von Bedeutung ist."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    Konstituente: Eine Konstituente ist eine Gruppe von Wörtern die zusammen eine (grammatikalische) Einheit bilden. Dabei kann diese Einheit aus entweder mehreren Wörtern oder auch teilweise einzelnen Wörtern bestehen die zusammen eine Phrase/Konstituente bilden. In der grammatischen Analyse hat eine Konstituente die Bedeutung, die Struktur eines Satzes zu verstehen und somit eine Sprache zu verstehen. Es ist ein wichtiger Bestandteil und dient zur Analyse und dazu, dass ein Computer eine Sprache überhaupt verstehen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3.2: _(3 Punkte)_\n",
    "Nennt sechs mögliche Tests, die benutzt werden können, um Konstituenten zu identifizieren. Beschreibt für jeden der Tests, wie er funktioniert und wie aussagekräftig er ist."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    1. Substitutionstest: Dieser Test fragt, ob man eine Wortfolge in einem Satz gegen eine andere Wortfolge so austauschen kann, dass wieder ein sinnvoller Satz entstehen kann, so ist das ein Indiz das die beiden Wortfolgen ein Konstituent bilden. Dieser Test ist je nach Sprache sehr aussagekräftig, vorallem in der deutschen Sprache, da Sätze in der deutschen Sprache in sehr vielen Weisen darstellbar sind.\n",
    "\n",
    "    2. Pronominalisierungstest: In diesem Test geht es darum, dass alles worauf man sich mit einen Pronomen bezieht eine Konstituente ist. Dabei ist dieser sehr aussagekräftig, da dieser ein Indiz ist und  Pronomen ein wichtiger Bestandteil der deutschen Sprache sind.\n",
    "\n",
    "    3. Fragetest: Was sich erfragen lässt ist eine Konstituente -> Wenn sich eine Gruppe von Wörtern erfragen lässt ist sie höchstwahrscheinlich eine Konstituente. Dies ist ebenfalls ein aussagekräftiger Test.\n",
    "\n",
    "    4. Permutationstest: Bei dem Permutationstest handelt es sich um einen Test, wo ohne Beeinträchtigung der Akzeptablität des Satzes die Wortfolgen umgestellt werden können. Dies ist ein Indiz dafür, dass es sich um ein Konstituent handelt.\n",
    "\n",
    "    5. Voranstellungstest: Die Voranstellbarkeit (das vorstellen an den Anfang des Satzes einer Wortfolge) ist ein starkes Indiz für den Konstituentenstatus. Dies ist ebenfalls extrem leicht zu prüfen und somit aussagekräftig.\n",
    "\n",
    "    6. Koordinationstest: Wenn sich Wortfolgen koordinieren lassen, sodass der Satz seine Bedeutung nicht verliert ist dies ein Indiz  für den Konstituentenstatus. Allerdings ist dies ein eher aufwendiger test und daher nicht so gut geeignet wie manch ein anderer. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3.3: _(1 Punkte)_\n",
    "Erklärt den Begriff **Attachment Ambiguität** am Beispiel des Satzes `She booked a flight having a meal.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "    Der Begriff beschreibt einen Satz, wo eine Prase mehrdeutig ist durch die Anordnung des Satzes. \n",
    "    In diesem Fall haben wir den Satz \"She booked a flight having a meal\". Hier ist es unklar, ob sich der Satz auf das \"having a meal\" oder das \"She booked a flight\" bezieht. Diese Art von Ambiguität sorgt für Verständnisprobleme."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
